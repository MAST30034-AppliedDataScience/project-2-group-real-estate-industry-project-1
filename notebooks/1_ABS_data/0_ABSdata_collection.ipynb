{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/ABS_SA2/ already exists, skipping creation.\n",
      "Directory ../../data/raw/ABS_SA2/ already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/ABS_SA2/'\n",
    "output_absolute_dir = '../../data/raw/ABS_SA2/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file already exists, skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "# Define URL and file paths\n",
    "url = \"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\"\n",
    "download_path = os.path.join(output_relative_dir, \"SA2_2021_AUST_SHP_GDA2020.zip\")\n",
    "extract_to_path = output_absolute_dir\n",
    "\n",
    "# Download and extract the file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading SA2 District Boundaries shapefile...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(\"Extracting shapefile...\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "\n",
    "    print(\"SA2 District Boundaries shapefile downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Zip file already exists, skipping download and extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/ABS_population/ already exists, skipping creation.\n",
      "Directory ../../data/raw/ABS_population/ already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/ABS_population/'\n",
    "output_absolute_dir = '../../data/raw/ABS_population/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Define URL and download paths\n",
    "url = \"https://www.abs.gov.au/statistics/people/population/regional-population/2022-23/32180DS0001_2022-23.xlsx\"\n",
    "download_path = os.path.join(output_relative_dir, \"32180DS0001_2022-23.xlsx\")\n",
    "\n",
    "# Download the Excel file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading ABS population dataset...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"File already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheet names: ['Contents', 'Table 1', 'Table 2', 'Table 3', 'Table 4', 'Table 5', 'Table 6', 'Table 7', 'Table 8', 'Table 9', 'Table 10']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and print sheet names\n",
    "xlsx = pd.ExcelFile(download_path)\n",
    "print(\"Available sheet names:\", xlsx.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GCCSA code    GCCSA name  SA4 code  SA4 name  SA3 code  SA3 name  \\\n",
      "0      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "1      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "2      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "3      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "4      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "\n",
      "      SA2 code       SA2 name      no.    no..1   no..2    %  no..3  no..4  \\\n",
      "0  201011001.0      Alfredton  18002.0  18997.0   995.0  5.5  140.0  695.0   \n",
      "1  201011002.0       Ballarat  11938.0  11809.0  -129.0 -1.1  -57.0 -213.0   \n",
      "2  201011005.0      Buninyong   7247.0   7323.0    76.0  1.0   15.0  -19.0   \n",
      "3  201011006.0      Delacombe  11798.0  12869.0  1071.0  9.1  133.0  898.0   \n",
      "4  201011007.0  Smythes Creek   4223.0   4268.0    45.0  1.1   11.0   31.0   \n",
      "\n",
      "   no..5    km2  persons/km2  \n",
      "0  160.0   52.7        360.4  \n",
      "1  141.0   12.4        954.0  \n",
      "2   80.0   51.6        142.0  \n",
      "3   40.0   34.2        376.7  \n",
      "4    3.0  104.7         40.8  \n",
      "Data saved to ../../data/raw/ABS_population/population_data_table_2.csv\n"
     ]
    }
   ],
   "source": [
    "sheet_name = xlsx.sheet_names[2]  # Adjust the index based on which sheet contains Table 2\n",
    "\n",
    "# Try loading the data again, adjust skiprows based on where Table 2 starts\n",
    "df = pd.read_excel(download_path, sheet_name=sheet_name, skiprows=6)  # Adjust skiprows if necessary\n",
    "\n",
    "# Check if the data was loaded correctly\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to CSV (optional step to save it for later use)\n",
    "csv_output_path = os.path.join(output_absolute_dir, \"population_data_table_2.csv\")\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "print(f\"Data saved to {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/Population_Forecast/ created.\n",
      "Directory ../../data/raw/Population_Forecast/ created.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/Population_Forecast/'\n",
    "output_absolute_dir = '../../data/raw/Population_Forecast/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading population forecast dataset...\n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "# Define URL and download paths\n",
    "url = \"https://www.planning.vic.gov.au/__data/assets/excel_doc/0028/691660/VIF2023_SA2_Pop_Hhold_Dwelling_Projections_to_2036_Release_2.xlsx\"\n",
    "download_path = os.path.join(output_relative_dir, \"VIF2023_Population_Forecast.xlsx\")\n",
    "\n",
    "# Download the Excel file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading population forecast dataset...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"File already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheet names: ['Contents', 'Explanatory Notes', 'Total_Population', 'Total_Dwellings', 'Total_Households', 'Dwellings_and_Households', 'Households_by_Type']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and print sheet names to find the right sheet\n",
    "xlsx = pd.ExcelFile(download_path)\n",
    "print(\"Available sheet names:\", xlsx.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GCCSA  SA4 Code  SA3 Code    SA2  code Region Type         Region     2021  \\\n",
      "1  2RVIC     201.0   20101.0  201011001.0         SA2      Alfredton  16841.0   \n",
      "2  2RVIC     201.0   20101.0  201011002.0         SA2       Ballarat  12071.0   \n",
      "3  2RVIC     201.0   20101.0  201011005.0         SA2      Buninyong   7229.0   \n",
      "4  2RVIC     201.0   20101.0  201011006.0         SA2      Delacombe  10648.0   \n",
      "5  2RVIC     201.0   20101.0  201011007.0         SA2  Smythes Creek   4211.0   \n",
      "\n",
      "           2026          2031          2036  \n",
      "1  20756.256163  23604.443836  26060.320807  \n",
      "2  11698.293593  11803.430603  11985.992387  \n",
      "3   7372.079773   7685.113372   8028.887243  \n",
      "4  15915.186041  20475.587469  24965.202439  \n",
      "5   4312.098530   4457.413406   4725.467837  \n",
      "Data saved to ../../data/raw/Population_Forecast/population_forecast_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the specific sheet\n",
    "sheet_name = xlsx.sheet_names[2]\n",
    "skiprows = 9  # Skip the first 9 rows to get to the table\n",
    "\n",
    "# Read the Excel file, keeping rows only up to row 533\n",
    "df = pd.read_excel(download_path, sheet_name=sheet_name, skiprows=skiprows)\n",
    "\n",
    "df = df.iloc[:524, :].drop(index=0)\n",
    "# df = df.iloc[:524, :]\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to CSV (optional step to save it for later use)\n",
    "csv_output_path = os.path.join(output_absolute_dir, \"population_forecast_data.csv\")\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "print(f\"Data saved to {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/Income_Statistics/ created.\n",
      "Directory ../../data/raw/Income_Statistics/ created.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/Income_Statistics/'\n",
    "output_absolute_dir = '../../data/raw/Income_Statistics/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading income statistics Excel file...\n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the URL and download path\n",
    "url = \"https://www.abs.gov.au/statistics/labour/earnings-and-working-conditions/personal-income-australia/2020-21-financial-year/Table%201%20-%20Total%20income%2C%20earners%20and%20summary%20statistics%20by%20geography%2C%202016-17%20to%202020-21.xlsx\"\n",
    "download_path = os.path.join(output_relative_dir, \"Income_Statistics_2020_2021.xlsx\")\n",
    "\n",
    "# Download the Excel file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading income statistics Excel file...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"File already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheet names: ['Contents', 'Table 1.1', 'Table 1.2', 'Table 1.3', 'Table 1.4', 'Table 1.5']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and list sheet names\n",
    "xlsx = pd.ExcelFile(download_path)\n",
    "print(\"Available sheet names:\", xlsx.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SA2    SA2 NAME     2016-17     2017-18     2018-19  \\\n",
      "0        Australia         NaN  13,675,002  14,069,078  14,425,034   \n",
      "1  New South Wales         NaN   4,344,142   4,466,939   4,569,649   \n",
      "2        101021007   Braidwood       2,261       2,311       2,362   \n",
      "3        101021008     Karabar       4,989       5,057       5,099   \n",
      "4        101021009  Queanbeyan       6,482       6,594       6,699   \n",
      "\n",
      "      2019-20     2020-21 2016-17.1 2017-18.1 2018-19.1  ... 2016-17.3  \\\n",
      "0  14,619,600  14,760,008        42        42        42  ...    48,083   \n",
      "1   4,614,939   4,603,736        42        42        42  ...    48,394   \n",
      "2       2,427       2,467        50        51        51  ...    40,790   \n",
      "3       5,131       5,103        42        42        42  ...    57,460   \n",
      "4       6,773       7,028        39        39        39  ...    55,033   \n",
      "\n",
      "  2017-18.3 2018-19.3 2019-20.3 2020-21.3 2016-17.4 2017-18.4 2018-19.4  \\\n",
      "0    49,805    51,389    52,338    54,890    63,508    64,247    65,954   \n",
      "1    50,153    51,818    52,849    55,854    66,055    67,195    68,813   \n",
      "2    42,003    41,593    44,246    46,640    52,068    51,639    51,192   \n",
      "3    59,295    61,777    62,946    65,564    63,294    63,808    66,381   \n",
      "4    57,848    60,119    61,724    63,528    61,747    62,878    65,809   \n",
      "\n",
      "  2019-20.4 2020-21.4  \n",
      "0    67,255    70,522  \n",
      "1    70,114    74,094  \n",
      "2    61,506    68,904  \n",
      "3    67,442    69,672  \n",
      "4    67,298    69,174  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Subtable saved to ../../data/raw/Income_Statistics/Income_Statistics_2020.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the specific sheet and the relevant subtable\n",
    "sheet_name = xlsx.sheet_names[4]  # Assuming the 4th subtable is in the 5th sheet\n",
    "df = pd.read_excel(download_path, sheet_name=sheet_name, skiprows=6)  # Skip first 6 rows\n",
    "\n",
    "# Extract row 7 and rows 653–1174\n",
    "df_subtable = pd.concat([df.iloc[[0]], df.iloc[645:1167, :]])\n",
    "\n",
    "# Remove the row where 'SA2' column is 'Australia'\n",
    "df_subtable = df_subtable[df_subtable['SA2'] != 'Australia']\n",
    "\n",
    "# Display the extracted subtable\n",
    "print(df.head())\n",
    "\n",
    "# Save the extracted subtable\n",
    "output_file_path = os.path.join(output_absolute_dir, \"Income_Statistics_2020.csv\")\n",
    "df_subtable.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Subtable saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "print"
=======
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/ABS_top50_school/'\n",
    "output_absolute_dir = '../../data/raw/ABS_top50_school/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/ABS_top50_school/ already exists, skipping creation.\n",
      "CSV file saved to: ../../data/landing/ABS_top50_school/vce_top_50_schools.csv\n",
      "     ?                                    School        Location  \\\n",
      "0    1                Ballarat Clarendon College        Ballarat   \n",
      "1    2                            Bialik College        Hawthorn   \n",
      "2    3                       Huntingtower School  Mount Waverley   \n",
      "3    4             Mount Scopus Memorial College         Burwood   \n",
      "4    5                       Ruyton Girls School             Kew   \n",
      "5    6  Yesodei Hatorah College Secondary Campus          Ormond   \n",
      "6    7                    Loreto Mandeville Hall          Toorak   \n",
      "7    8              Mentone Girls Grammar School         Mentone   \n",
      "8    9            Macrobertson Girls High School       Melbourne   \n",
      "9   10              Korowa Anglican Girls School       Glen Iris   \n",
      "10  11                      St Catherines School          Toorak   \n",
      "11  12                  Haileybury Girls College     Keysborough   \n",
      "12  13                     Melbourne High School     South Yarra   \n",
      "13  14                        Nossal High School         Berwick   \n",
      "14  15                               Sacre Coeur       Glen Iris   \n",
      "15  16                     The King David School        Armadale   \n",
      "16  17                   Brighton Grammar School        Brighton   \n",
      "17  18                    Leibler Yavneh College     Elsternwick   \n",
      "18  19                      Fintona Girls School          Balwyn   \n",
      "19  20                  Melbourne Grammar School       Melbourne   \n",
      "20  21                        Haileybury College     Keysborough   \n",
      "21  22                    Trinity Grammar School             Kew   \n",
      "22  23                         St Kevins College          Toorak   \n",
      "23  24           Strathcona Girls Grammar School      Canterbury   \n",
      "24  25               Presbyterian Ladies College         Burwood   \n",
      "25  26               Yarra Valley Grammar School        Ringwood   \n",
      "26  27                John Monash Science School         Clayton   \n",
      "27  28                    Mentone Grammar School         Mentone   \n",
      "28  29                 Camberwell Grammar School      Canterbury   \n",
      "29  30                       St Leonards College   Brighton East   \n",
      "30  31           Camberwell Girls Grammar School      Canterbury   \n",
      "31  32            Goulburn Valley Grammar School      Shepparton   \n",
      "32  33                  Suzanne Cory High School        Werribee   \n",
      "33  34                Beth Rivkah Ladies College   St Kilda East   \n",
      "34  35                             Siena College      Camberwell   \n",
      "35  36      Penleigh and Essendon Grammar School     Keilor East   \n",
      "36  37                   Melbourne Girls Grammar     South Yarra   \n",
      "37  38                    Lauriston Girls School        Armadale   \n",
      "38  39                    Firbank Grammar School        Brighton   \n",
      "39  40              Ivanhoe Girls Grammar School         Ivanhoe   \n",
      "40  41                            Scotch College        Hawthorn   \n",
      "41  42      Lowther Hall Anglican Grammar School        Essendon   \n",
      "42  43                  Genazzano F.C.J. College             Kew   \n",
      "43  44                          Yeshivah College   St Kilda East   \n",
      "44  45                St Michaels Grammar School        St Kilda   \n",
      "45  46                   Mallacoota P-12 College      Mallacoota   \n",
      "46  47                    Shelford Girls Grammar       Caulfield   \n",
      "47  48                            Toorak College     Mount Eliza   \n",
      "48  49                          Corryong College        Corryong   \n",
      "49  50                   Star of the Sea College        Brighton   \n",
      "\n",
      "   MedianVCE Score\\n\\n\\n  ? VCE40+ %\\n\\n\\n  ?  \n",
      "0                        39              45.8  \n",
      "1                        37              34.1  \n",
      "2                        37              33.8  \n",
      "3                        37              31.5  \n",
      "4                        37              31.4  \n",
      "5                        37                20  \n",
      "6                        36              29.6  \n",
      "7                        36              29.4  \n",
      "8                        36              29.3  \n",
      "9                        36                29  \n",
      "10                       36              28.9  \n",
      "11                       36              28.6  \n",
      "12                       36              27.9  \n",
      "13                       36                27  \n",
      "14                       36                27  \n",
      "15                       36              26.5  \n",
      "16                       36              24.5  \n",
      "17                       36              23.1  \n",
      "18                       35              27.7  \n",
      "19                       35              27.1  \n",
      "20                       35              26.3  \n",
      "21                       35              25.7  \n",
      "22                       35                24  \n",
      "23                       35              23.7  \n",
      "24                       35                23  \n",
      "25                       35              22.3  \n",
      "26                       35              21.5  \n",
      "27                       35              21.1  \n",
      "28                       35                21  \n",
      "29                       35              20.7  \n",
      "30                       35              19.5  \n",
      "31                       35              19.2  \n",
      "32                       35                19  \n",
      "33                       35              18.9  \n",
      "34                       34              20.4  \n",
      "35                       34              20.3  \n",
      "36                       34              19.9  \n",
      "37                       34              19.8  \n",
      "38                       34              18.9  \n",
      "39                       34              18.6  \n",
      "40                       34              18.4  \n",
      "41                       34              18.1  \n",
      "42                       34                18  \n",
      "43                       34              17.9  \n",
      "44                       34              17.6  \n",
      "45                       34              16.7  \n",
      "46                       34              16.1  \n",
      "47                       34              15.6  \n",
      "48                       34              15.4  \n",
      "49                       34              13.5  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define directory\n",
    "output_relative_dir = '../../data/landing/ABS_top50_school/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "# URL of the target webpage\n",
    "url = \"https://www.topscores.co/Vic/vce-school-rank-median-vce/2023/\"\n",
    "\n",
    "# Send a request to fetch the page content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the table on the page\n",
    "table = soup.find('table')\n",
    "\n",
    "# Extract headers\n",
    "headers = []\n",
    "for th in table.find_all('th'):\n",
    "    headers.append(th.text.strip())\n",
    "\n",
    "# Extract table rows and ensure empty rows are handled properly\n",
    "rows = []\n",
    "for tr in table.find_all('tr'):\n",
    "    cells = [td.text.strip() for td in tr.find_all('td')]\n",
    "    # Ensure there are cells in the row\n",
    "    if len(cells) == len(headers):  # This checks that the row has the correct number of cells\n",
    "        rows.append(cells)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Display the first 50 rows\n",
    "df_top_50 = df.head(50)\n",
    "\n",
    "# Define the path for saving the CSV\n",
    "relative_path = os.path.join(output_relative_dir, 'vce_top_50_schools.csv')\n",
    "\n",
    "# Save the CSV to the landing directory\n",
    "df_top_50.to_csv(relative_path, index=False)\n",
    "\n",
    "print(f\"CSV file saved to: {relative_path}\")\n",
    "\n",
    "# Show the result\n",
    "print(df_top_50)\n"
>>>>>>> Stashed changes
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
