{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Ran Zhang, Aug 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/ABS_SA2/ already exists, skipping creation.\n",
      "Directory ../../data/raw/ABS_SA2/ already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/ABS_SA2/'\n",
    "output_absolute_dir = '../../data/raw/ABS_SA2/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file already exists, skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "# Define URL and file paths\n",
    "url = \"https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA2020.zip\"\n",
    "download_path = os.path.join(output_relative_dir, \"SA2_2021_AUST_SHP_GDA2020.zip\")\n",
    "extract_to_path = output_absolute_dir\n",
    "\n",
    "# Download and extract the file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading SA2 District Boundaries shapefile...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    print(\"Extracting shapefile...\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to_path)\n",
    "\n",
    "    print(\"SA2 District Boundaries shapefile downloaded and extracted successfully.\")\n",
    "else:\n",
    "    print(\"Zip file already exists, skipping download and extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/ABS_population/ already exists, skipping creation.\n",
      "Directory ../../data/raw/ABS_population/ already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/ABS_population/'\n",
    "output_absolute_dir = '../../data/raw/ABS_population/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Define URL and download paths\n",
    "url = \"https://www.abs.gov.au/statistics/people/population/regional-population/2022-23/32180DS0003_2001-23.xlsx\"\n",
    "download_path = os.path.join(output_relative_dir, \"32180DS0003_2001-23.xlsx\")\n",
    "\n",
    "# Download the Excel file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading ABS population dataset...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"File already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheet names: ['Contents', 'Table 1', 'Table 2', 'Table 3', 'Table 4', 'Table 5']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and print sheet names\n",
    "xlsx = pd.ExcelFile(download_path)\n",
    "print(\"Available sheet names:\", xlsx.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GCCSA code    GCCSA name  SA4 code  SA4 name  SA3 code  SA3 name  \\\n",
      "1      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "2      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "3      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "4      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "5      2RVIC  Rest of Vic.     201.0  Ballarat   20101.0  Ballarat   \n",
      "\n",
      "      SA2 code       SA2 name      no.    no..1  ...   no..13   no..14  \\\n",
      "1  201011001.0      Alfredton   5756.0   6092.0  ...  10338.0  11039.0   \n",
      "2  201011002.0       Ballarat  11497.0  11708.0  ...  12327.0  12300.0   \n",
      "3  201011005.0      Buninyong   5320.0   5399.0  ...   7082.0   7191.0   \n",
      "4  201011006.0      Delacombe   4154.0   4225.0  ...   6583.0   6846.0   \n",
      "5  201011007.0  Smythes Creek   3317.0   3378.0  ...   3945.0   3966.0   \n",
      "\n",
      "    no..15   no..16   no..17   no..18   no..19   no..20   no..21   no..22  \n",
      "1  11852.0  12649.0  13537.0  14434.0  15507.0  16841.0  18002.0  18997.0  \n",
      "2  12301.0  12266.0  12244.0  12320.0  12196.0  12071.0  11938.0  11809.0  \n",
      "3   7311.0   7409.0   7418.0   7458.0   7377.0   7229.0   7247.0   7323.0  \n",
      "4   7195.0   7622.0   8183.0   8890.0   9755.0  10648.0  11798.0  12869.0  \n",
      "5   3990.0   4004.0   4042.0   4112.0   4152.0   4211.0   4223.0   4268.0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Data saved to ../../data/raw/ABS_population/population_data_table_2.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file, starting from row 7 \n",
    "sheet_name = xlsx.sheet_names[1]  # Adjust the index based on the sheet containing the relevant table\n",
    "df = pd.read_excel(download_path, sheet_name=sheet_name, skiprows=6)\n",
    "\n",
    "# Select row 7 (which is now index 0) and rows 650-1171 (which are now indices 642 to 1163)\n",
    "df_filtered = pd.concat([df.iloc[[0]], df.iloc[642:1164]])\n",
    "\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "df_filtered = df_filtered.drop(index=0)\n",
    "\n",
    "# Check if the data was filtered correctly\n",
    "print(df_filtered.head())\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file\n",
    "csv_output_path = os.path.join(output_absolute_dir, \"population_data_table_2.csv\")\n",
    "df_filtered.to_csv(csv_output_path, index=False)\n",
    "print(f\"Data saved to {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/Population_Forecast/ already exists, skipping creation.\n",
      "Directory ../../data/raw/ABS_population/ already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/Population_Forecast/'\n",
    "output_absolute_dir = '../../data/raw/ABS_population/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Define URL and download paths\n",
    "url = \"https://www.planning.vic.gov.au/__data/assets/excel_doc/0028/691660/VIF2023_SA2_Pop_Hhold_Dwelling_Projections_to_2036_Release_2.xlsx\"\n",
    "download_path = os.path.join(output_relative_dir, \"VIF2023_Population_Forecast.xlsx\")\n",
    "\n",
    "# Download the Excel file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading population forecast dataset...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"File already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheet names: ['Contents', 'Explanatory Notes', 'Total_Population', 'Total_Dwellings', 'Total_Households', 'Dwellings_and_Households', 'Households_by_Type']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and print sheet names to find the right sheet\n",
    "xlsx = pd.ExcelFile(download_path)\n",
    "print(\"Available sheet names:\", xlsx.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GCCSA  SA4 Code  SA3 Code    SA2  code Region Type         Region     2021  \\\n",
      "1  2RVIC     201.0   20101.0  201011001.0         SA2      Alfredton  16841.0   \n",
      "2  2RVIC     201.0   20101.0  201011002.0         SA2       Ballarat  12071.0   \n",
      "3  2RVIC     201.0   20101.0  201011005.0         SA2      Buninyong   7229.0   \n",
      "4  2RVIC     201.0   20101.0  201011006.0         SA2      Delacombe  10648.0   \n",
      "5  2RVIC     201.0   20101.0  201011007.0         SA2  Smythes Creek   4211.0   \n",
      "\n",
      "           2026          2031          2036  \n",
      "1  20756.256163  23604.443836  26060.320807  \n",
      "2  11698.293593  11803.430603  11985.992387  \n",
      "3   7372.079773   7685.113372   8028.887243  \n",
      "4  15915.186041  20475.587469  24965.202439  \n",
      "5   4312.098530   4457.413406   4725.467837  \n",
      "Data saved to ../../data/raw/ABS_population/ABS_population_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the specific sheet\n",
    "sheet_name = xlsx.sheet_names[2]\n",
    "skiprows = 9  # Skip the first 9 rows to get to the table\n",
    "\n",
    "# Read the Excel file, keeping rows only up to row 533\n",
    "df = pd.read_excel(download_path, sheet_name=sheet_name, skiprows=skiprows)\n",
    "\n",
    "df = df.iloc[:524, :].drop(index=0)\n",
    "# df = df.iloc[:524, :]\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "print(df.head())\n",
    "\n",
    "# Save the DataFrame to CSV (optional step to save it for later use)\n",
    "csv_output_path = os.path.join(output_absolute_dir, \"ABS_population_data.csv\")\n",
    "df.to_csv(csv_output_path, index=False)\n",
    "print(f\"Data saved to {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory ../../data/landing/Income_Statistics/ already exists, skipping creation.\n",
      "Directory ../../data/raw/Income_Statistics/ already exists, skipping creation.\n"
     ]
    }
   ],
   "source": [
    "# Define directories\n",
    "output_relative_dir = '../../data/landing/Income_Statistics/'\n",
    "output_absolute_dir = '../../data/raw/Income_Statistics/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "    print(f\"Directory {output_relative_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_relative_dir} already exists, skipping creation.\")\n",
    "\n",
    "if not os.path.exists(output_absolute_dir):\n",
    "    os.makedirs(output_absolute_dir)\n",
    "    print(f\"Directory {output_absolute_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_absolute_dir} already exists, skipping creation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Define the URL and download path\n",
    "url = \"https://www.abs.gov.au/statistics/labour/earnings-and-working-conditions/personal-income-australia/2020-21-financial-year/Table%201%20-%20Total%20income%2C%20earners%20and%20summary%20statistics%20by%20geography%2C%202016-17%20to%202020-21.xlsx\"\n",
    "download_path = os.path.join(output_relative_dir, \"Income_Statistics_2016_2020.xlsx\")\n",
    "\n",
    "# Download the Excel file\n",
    "if not os.path.exists(download_path):\n",
    "    print(\"Downloading income statistics Excel file...\")\n",
    "    response = requests.get(url)\n",
    "    with open(download_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"File already exists, skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sheet names: ['Contents', 'Table 1.1', 'Table 1.2', 'Table 1.3', 'Table 1.4', 'Table 1.5']\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file and list sheet names\n",
    "xlsx = pd.ExcelFile(download_path)\n",
    "print(\"Available sheet names:\", xlsx.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               SA2    SA2 NAME     2016-17     2017-18     2018-19  \\\n",
      "0        Australia         NaN  13,675,002  14,069,078  14,425,034   \n",
      "1  New South Wales         NaN   4,344,142   4,466,939   4,569,649   \n",
      "2        101021007   Braidwood       2,261       2,311       2,362   \n",
      "3        101021008     Karabar       4,989       5,057       5,099   \n",
      "4        101021009  Queanbeyan       6,482       6,594       6,699   \n",
      "\n",
      "      2019-20     2020-21 2016-17.1 2017-18.1 2018-19.1  ... 2016-17.3  \\\n",
      "0  14,619,600  14,760,008        42        42        42  ...    48,083   \n",
      "1   4,614,939   4,603,736        42        42        42  ...    48,394   \n",
      "2       2,427       2,467        50        51        51  ...    40,790   \n",
      "3       5,131       5,103        42        42        42  ...    57,460   \n",
      "4       6,773       7,028        39        39        39  ...    55,033   \n",
      "\n",
      "  2017-18.3 2018-19.3 2019-20.3 2020-21.3 2016-17.4 2017-18.4 2018-19.4  \\\n",
      "0    49,805    51,389    52,338    54,890    63,508    64,247    65,954   \n",
      "1    50,153    51,818    52,849    55,854    66,055    67,195    68,813   \n",
      "2    42,003    41,593    44,246    46,640    52,068    51,639    51,192   \n",
      "3    59,295    61,777    62,946    65,564    63,294    63,808    66,381   \n",
      "4    57,848    60,119    61,724    63,528    61,747    62,878    65,809   \n",
      "\n",
      "  2019-20.4 2020-21.4  \n",
      "0    67,255    70,522  \n",
      "1    70,114    74,094  \n",
      "2    61,506    68,904  \n",
      "3    67,442    69,672  \n",
      "4    67,298    69,174  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Subtable saved to ../../data/raw/Income_Statistics/Income_Statistics_2020.csv\n"
     ]
    }
   ],
   "source": [
    "# Read the specific sheet and the relevant subtable\n",
    "sheet_name = xlsx.sheet_names[4]  # Assuming the 4th subtable is in the 5th sheet\n",
    "df = pd.read_excel(download_path, sheet_name=sheet_name, skiprows=6)  # Skip first 6 rows\n",
    "\n",
    "# Extract row 7 and rows 653–1174\n",
    "df_subtable = pd.concat([df.iloc[[0]], df.iloc[645:1167, :]])\n",
    "\n",
    "# Remove the row where 'SA2' column is 'Australia'\n",
    "df_subtable = df_subtable[df_subtable['SA2'] != 'Australia']\n",
    "\n",
    "# Display the extracted subtable\n",
    "print(df.head())\n",
    "\n",
    "# Save the extracted subtable\n",
    "output_file_path = os.path.join(output_absolute_dir, \"Income_Statistics_2020.csv\")\n",
    "df_subtable.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Subtable saved to {output_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
